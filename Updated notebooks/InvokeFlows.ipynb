{"cells": [{"metadata": {"id": "71aafcb6e646430a8dc26efb2c1c4e1e"}, "cell_type": "markdown", "source": "# Modeler Flows Jobs: Orchestration\nThis notebook provides an example of invoking *3 Modeler flows* that have been configured as a Job.  \n\nMore information about APIs (**Watson Data API**) that are used in this notebook is available in product documentation: https://cloud.ibm.com/apidocs/watson-data-api-cpd\n\nAPIs are typically used for *automation* and *orchestration*. We implemented code in a notebook that's a part of a Watson Studio project for ease of demonstration. Sample Python code can also be saved as a Python script and executed from an external environment (such as a CI/CD platform). \n\nSince we use the terms automation and orchestration, let's define them. **Automation** is invoking the process programatically without human interaction, usually based on a schedule or a trigger. **Orchestration** is combining multiple steps into a single process.  \n\nAny type of asset that can be configured to run as a *Job* in a \"Watson Studio project\" can be used with this API. Current version of Cloud Pak for Data supports jobs for:\n- Modeler flows\n- Notebooks\n- Python scripts\n- R scripts\n- Refinery flows\n\nThere are several use cases for automation and orchestration of jobs. Here are a few examples:\n- Automate and/or orchestrate data preparation (implemented in scripts, flows, or notebooks) based on a schedule or an external trigger\n- Automate and/or orchestrate model retraining (implemented in scripts, flows, or notebooks) based on a schedule or an external trigger\n- Automate and/or orchestrate testing and deployment of data science assets into Deployment Spaces. \n\nIn this notebook we will show a simple example which you can expand to fit your use cases. \n\n*Note: This notebook has been created and tested in Cloud Pak for Data Hybrid Cloud*"}, {"metadata": {"id": "147f895e27ae4f828be3432e452ee225"}, "cell_type": "markdown", "source": "## Step 1: Manually create Modeler Flows Jobs\nWhile it's possible to create a job with an API, we think that in most scenarios jobs will be created and tested manually, and then used with automation/orchestration.\n\nCreate a Job for any Modeler Flow that you want to test. For example, in this project we provide 3 Modeler Flows: *Data Preparation*, *Model Scoring C5*, and *Post Scoring Rules*\n\n1. Open each flow and save a version  and save a version (look for Versions icon in the rigth top toolbar - same button as for Output). Jobs require versioning of notebooks and flows.\n2. Create a job - use the Job icon in the top toolbar. \n3. Test the job in the project UI. "}, {"metadata": {"id": "2270145232734ae7acd567860348c7c9"}, "cell_type": "markdown", "source": "## Step 2: Invoke the Jobs\nTo construct the API call, we will need to get the following information:\n1. *Authorizaton token*: this token is required for all calls to Cloud Pak for Data API\n2. *Project id*: needed as a paramter for the job invocation REST request\n3. *Asset id*: needed as a parameter for the job invocation REST request"}, {"metadata": {"id": "41e5ae9e75084de4843b02ce355c9f50"}, "cell_type": "code", "source": "# If you're running in a Watson Studio project, the token is available as a local variable\n#token = os.environ['USER_ACCESS_TOKEN']\n\n#In this notebook we will demonstrate retrieving a token via API, which will be required for code running outside of Cloud Pak for Data", "execution_count": null, "outputs": []}, {"metadata": {"id": "07c85a1bae184ceaa2553e7856c530fd"}, "cell_type": "code", "source": "# Define variables that need to be changed or reused\n\n# TO DO: change to the hostname (and port, if defined) of your cluster\n\n# If using a market cluster in North America (in TEC), the value should be 'https://ibm-nginx-svc.cpdmkt.svc' (this value is the same for ALL clusters)\n# For all other clusters, use the CPD URL that ends with .oi, for example, 'https://cpdmkt-cpd-cpdmkt.apps.cpd.12-181-164-84.nip.io'\ncpd_hostname = \"***\"\n\n# TO DO: change to userid and password that exists in the CPD cluster. These credentials will be used to generate a token\nusername = \"***\"\npassword = \"***\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "4596b5602c9443a5894d5059d8509801"}, "cell_type": "code", "source": "import requests\nimport json\n\nheaders = {\n    'Content-Type': 'application/json',\n}\n\ndata = '{\"username\":\\\"' + username + '\\\",\"password\":\\\"' + password + '\\\"}\\''\n\n# Construct the request URL\nrequestURL = cpd_hostname + \"/icp4d-api/v1/authorize\"\n\nresponse = requests.post(requestURL, headers=headers, data=data, verify=False)\n\nresponseContent = response.content\ntoken = json.loads(responseContent)['token']\n\n# Print token just for a demo - remove in production\nprint(token)", "execution_count": null, "outputs": []}, {"metadata": {"id": "b3b0f7d0cfe4461596978157a80fcc2b"}, "cell_type": "code", "source": "#Next, we will get the project id. We can use the project-lib library to perform this task. \n\n# Import the lib\nfrom project_lib import Project\nproject = Project.access()\n\nprojectMetadata = project.get_metadata()\n\n# Let's print the output. \n# Metadata is returned as a nested dictionary. Project id is listed as 'guid'\nprint(type(projectMetadata))\nprint(projectMetadata)", "execution_count": null, "outputs": []}, {"metadata": {"id": "52db350fbb9248d8912c5f87e2b8fd98"}, "cell_type": "code", "source": "# Get the project id and print it for verification\nprojectID = projectMetadata['metadata']['guid']\nprint(projectID)", "execution_count": null, "outputs": []}, {"metadata": {"id": "55be665f51a84a428ddf4d1445ef102f"}, "cell_type": "code", "source": "# Get the Job id\nproject.get_assets()", "execution_count": null, "outputs": []}, {"metadata": {"id": "054e51a95e4748d9bea08b414115fb53"}, "cell_type": "code", "source": "# Manually look up the the asset_ids for the Modeler Jobs that you created and save them in a variable. asset_id will be used to construct REST request URL. \n# Make sure to get the ID for the Job, and not Job Run. \njobID_1 = \"3266f869-aeef-4e80-95ec-dec5eef127ed\"\njobID_2 = \"a273928b-74ae-4efe-9750-e218a9b160e3\"\njobID_3 = \"9b40b525-0c3e-48ae-9b9f-128f915593e2\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "33e279a4-b633-4960-a1de-de3c40b1eecd"}, "cell_type": "code", "source": "# We can reuse the header and body (dataDict) for invocation of all jobs\n\nheaders = {\n     'Authorization': 'Bearer ' + token,\n     'accept': 'application/json',\n     'Content-Type': 'application/json'\n}\n\n\n# This JSON body can be used with any job invocation, even if the job defintion doesn't \n\ndataDict = {\n   \"job_run\": {\n        \"configuration\": {\n            \"env_variables\": [\n                \"variable1=test1\",\n                \"variable2=test2\"\n            ]\n        }\n    }\n}\n\ndata = json.dumps(dataDict)\n\n# Print if debugging\n# print(headers)\n# print(data)", "execution_count": null, "outputs": []}, {"metadata": {"id": "d237c6c344644eb888142ddd9eda75a4"}, "cell_type": "code", "source": "#Construct the URL for invoking the job. We are using this REST endpoint: https://cloud.ibm.com/apidocs/watson-data-api-cpd#job-runs-create\nurl1 = cpd_hostname + \"/v2/jobs/\" + jobID_1 + \"/runs?project_id=\" + projectID\nurl2 = cpd_hostname + \"/v2/jobs/\" + jobID_2 + \"/runs?project_id=\" + projectID\nurl3 = cpd_hostname + \"/v2/jobs/\" + jobID_3 + \"/runs?project_id=\" + projectID\n\n# print(url1)\n# print(url2)\n# print(url3)", "execution_count": null, "outputs": []}, {"metadata": {"id": "39dec790d66347a38c68721ab1a3218c"}, "cell_type": "code", "source": "# Invoke the 1st job\nresponse = requests.post(url1, headers=headers, data=data, verify=False)\n\nresponseContent = response.content\n# print(responseContent)", "execution_count": null, "outputs": []}, {"metadata": {"id": "bcc7226e1df647cfa16ac0d8233b7caf"}, "cell_type": "code", "source": "# If we want to check the job status, we need to get the run ID, which is called asset_id\nrunID = json.loads(responseContent)['metadata']['asset_id']\nprint(runID)", "execution_count": null, "outputs": []}, {"metadata": {"id": "d86ac301cf194fea866955769bcb574a"}, "cell_type": "code", "source": "url = cpd_hostname + \"/v2/jobs/\" + jobID_1 + \"/runs/\" + runID + \"?project_id=\" + projectID\nprint(url)", "execution_count": null, "outputs": []}, {"metadata": {"id": "cb77f339be234c0a9097e38e2af83732"}, "cell_type": "code", "source": "response = requests.get(url, headers=headers, verify=False)\nresponseContent = response.content\nprint(responseContent)", "execution_count": null, "outputs": []}, {"metadata": {"id": "2795a54f6b93475187e6ca5fc1bf95aa"}, "cell_type": "code", "source": "# Job Status is reported in variable \"state\"\njobStatus = json.loads(responseContent)['entity']['job_run']['state']\nprint(jobStatus)", "execution_count": null, "outputs": []}, {"metadata": {"id": "6a06af01dca04e6d91967e1117906f4d"}, "cell_type": "code", "source": "# Status look up can also be implemented in a loop. This is useful when you need to invoke a 2nd job after the completion of the first one\nimport time\n\nwhile jobStatus == \"Starting\" or jobStatus == \"Running\":\n  response = requests.get(url, headers=headers, verify=False)\n  responseContent = response.content\n  jobStatus = json.loads(responseContent)['entity']['job_run']['state']\n  print(jobStatus)\n# Wait for 20 seconds before checking status again\n  time.sleep(20)", "execution_count": null, "outputs": []}, {"metadata": {"id": "e42a6d9887cf4399b36b205061573503"}, "cell_type": "code", "source": "# It's possible to refactor this code to create a function for invoking jobs. We repeat the code in this example for ease of debugging\n\n# Invoke the 2nd job\nresponse = requests.post(url2, headers=headers, data=data, verify=False)\n\nresponseContent = response.content\n\n# If we want to check the job status, we need to get the run ID, which is called asset_id\nrunID = json.loads(responseContent)['metadata']['asset_id']\n\nurl = cpd_hostname + \"/v2/jobs/\" + jobID_2 + \"/runs/\" + runID + \"?project_id=\" + projectID\n\nresponse = requests.get(url, headers=headers, verify=False)\nresponseContent = response.content\nprint(responseContent)", "execution_count": null, "outputs": []}, {"metadata": {"id": "90858c9d123c4c45812c08bb077e6e9e"}, "cell_type": "code", "source": "jobStatus = json.loads(responseContent)['entity']['job_run']['state']\nprint(jobStatus)", "execution_count": null, "outputs": []}, {"metadata": {"id": "516ccadf4f1e4047991b4cf695a81662"}, "cell_type": "code", "source": "while jobStatus == \"Starting\" or jobStatus == \"Running\":\n  response = requests.get(url, headers=headers, verify=False)\n  responseContent = response.content\n  jobStatus = json.loads(responseContent)['entity']['job_run']['state']\n  print(jobStatus)\n# Wait for 20 seconds before checking status again\n  time.sleep(20)", "execution_count": null, "outputs": []}, {"metadata": {"id": "1de8cc06bb87432f997a052f191d80ad"}, "cell_type": "code", "source": "# Invoke the 3rd job\nresponse = requests.post(url3, headers=headers, data=data, verify=False)\n\nresponseContent = response.content\n\n# If we want to check the job status, we need to get the run ID, which is called asset_id\nrunID = json.loads(responseContent)['metadata']['asset_id']\n\nurl = cpd_hostname + \"/v2/jobs/\" + jobID_3 + \"/runs/\" + runID + \"?project_id=\" + projectID\n\nresponse = requests.get(url, headers=headers, verify=False)\nresponseContent = response.content\nprint(responseContent)", "execution_count": null, "outputs": []}, {"metadata": {"id": "cd696b7611c24118990f0099d05dfed7"}, "cell_type": "code", "source": "jobStatus = json.loads(responseContent)['entity']['job_run']['state']\nprint(jobStatus)", "execution_count": null, "outputs": []}, {"metadata": {"id": "e0b41744452d4ec7862ea9ae049674ad"}, "cell_type": "code", "source": "while jobStatus == \"Starting\" or jobStatus == \"Running\":\n  response = requests.get(url, headers=headers, verify=False)\n  responseContent = response.content\n  jobStatus = json.loads(responseContent)['entity']['job_run']['state']\n  print(jobStatus)\n# Wait for 10 seconds before checking status again\n  time.sleep(10)", "execution_count": null, "outputs": []}, {"metadata": {"id": "ea828108b7304f5fbcbb0de7e2ff2fda"}, "cell_type": "markdown", "source": "**Written by: Elena Lowery, April 2021**"}, {"metadata": {"id": "8587741708a4412ca7be570cb8591ebe"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}